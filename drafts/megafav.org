#+title: /BDDs, ANF, and my two #megafavnumbers/

* =00:30= 00 Intro:#megafavnumbers
Hi there. My name is michal, and this video
is about boolean expressions and my two #megafavnumbers.

#megafavnumbers is a youtube playlist where a bunch
of really great math-related channels are sharing
their favorite numbers greater than 1 million, and
they've opened it up to viewers to submit their own.

I wasn't really sure I had a favorite number, but
then I realized there are two huge numbers I think
about quite a bit.

: X =             4,294,967,296
: K =   614,889,782,588,491,410

The first one is probably at least vaguely familiar to
other programmers out there. It's just 2^32 power.

The second is an example of something called a primorial.
It's the product of the first 15 prime numbers. It's also
the biggest primorial that you can store in a 64-bit
register.

I don't know if there are any interesting theorems related
to these numbers, but they both play a big role in one of
my main programming projects, which is a rust crate
(or library) that I call bex.

So, that's what I'm going to talk about.

* =00:15= 01 bex intro
# show crates.rs / github page / docs as i talk

Bex is short for "boolean expression", and not surprisingly, it
provides some data structures for working with large boolean
expressions.

https://crates.io/crates/bex
https://github.com/tangentstorm/bex
https://docs.rs/bex/0.1.4/bex/

This video is about boolean expressions in general,
a little bit about bex in particular, and what those
two numbers have to do with it.

And even though bex is written in rust, if you've ever
seen my channel before you probably won't be too
surprised to find another language called J making
more than one appearance.

* =01:30= 02 BDD intro
** bex does BDDs
Bex has a number of ways to represent boolean expressions.
But it started with this idea called a binary decision diagram, or bdd.

If you look up binary decision diagram on wikipedia
you'll see this.

On the left here is a fully expanded BDD, also called a decision tree.
The idea is you have three input bits. x1 x2 x3
This dotted line says what to do if the input is 0.
The solid line says what to do if it's 1.

So for example this line in the truth table says
inputs 0 1 1 give output 1.
follow it on the graph and we get the same thing.

On the right here is what's called a reduced and ordered BDD.
Ordered just means the variables are in order from top to bottom.
And reduced means that all the redundant information is stripped out.

** demo in VUE
i made a copy of the diagram to show how it works.

at the bottom here we have the bits of the truth table
and again the fully expanded decision tree
but notice that these nodes at the bottom branch to the same place on both sides
so we can replace them with the leaf node
but also we don't need so many copies of this node.
generalize a tree with a dag
keep doing that and we have a fully reduced bdd

and with those two rules
we can convert any decision tree
into a fully reduced
binary decision diagram

* =01:00= 03 about bdds
BDDs have lots of nice features.

They're a canonical representation for boolean expressions,
that means that if two expressions have the same truth table
they have the same bdd.

But because the information is compressed, it's possible
to work with what would be incredibly huge truth tables
efficiently.

I'm barely scratching the surface here, but they've
got all sorts of interesting applications.

Donald Knuth dedicated a whole  section to them
in the art of computer programming, and he gave a couple
great lectures about them (and some related graph structures)
that I'll link in the description.

* =00:15= 04 bdd lab (bdd as learning project)
For me, building a BDD system is just a nice way to learn a new programming languages.

Sometimes I make tetris
https://github.com/learnprogramming/learntris

sometimes i make a bdd.
https://github.com/tangentstorm/bdd-labs/

I've made implementations in elixir, j, python, pascal.

So when I decided to learn rust, I started writing yet
another toy bdd system.

But Rust turned out to be kind of an ideal language
for writing systems like this. I gives you a tremendous
amount of expressive power while still letting you compile
extremely fast executables, and most importantly, it
promised to make it a whole lot easier to write
threadsafe code.

So eventually I did that. My little learning project
turned into a fairly fast multi-threaded BDD solver,
I decided I was going to keep working on it.

Somewhere along the line, I decided to make it open
source and stuck it up on github.

* =02:00= 05 bex-shell demo
ok so let's see bex in action.

generally, you'd use it as a library in a normal rust program,
but one of the example programs is a little interactive shell.

If you clone the repo, and you have rust installed, you can
compile and run the shell like this:

: cargo run

Cargo is just the standard build tool that comes with rust.

And you have to tell it what to run:

: cargo run --bin bex-shell

I actually don't use this very much yet, so it's really primitive.

It's basically the simplest sort of interpreter you can make,
which is an interpreter for reverse polish notation.

These little brackets show you a stack of values. Right now it's empty.
And as you type things, at the prompt, they'll go onto the stack.

So let's enter that same example expression.

: $1 <enter> puts x1 on the stack

actually you can use x0 but i'll stick with the example

~ for not
or you can use the word not

: $2 ~ $3 not

this is what bex call an AST.
it means abstract syntax tree, which is an idea from parsing.
it just means we're trying to directly represent the as the person types it.
in this case, we're using rpn so you hardly need a parser at all.
but that's what i call it.
it's also sort of a circuit diagram.

: dup sho $3

dup copies the top number on the stack

not dup sho (shows ~3)
and dup sho

$x1 $x2 and or
dup sho

$x2 $x3 and or
dup sho

okay so now let's convert that to a bdd
dup bdd

so here's how bex draws the bdd.
it's not exactly the same as what we saw before.
the main difference is that x3 is at the top.

putting the smallest input at the top is kind of
the industry standard, but in the last version,
i made the decision to break with tradition and reverse it.
the reason has everything to do with that first
megafav number I mentioned- 2^32 power.
But we'll get to that in a bit.

In any case, other than swapping the order of x1 and x3,
i promise you these two graphs have exactly the same structure.

Normally, that wouldn't be the case. In general, swapping
the order of variables can dramatically change the shape of
the BDD, but in this particular case, swapping x1 and x3
gives you the exact same function.

Let's prove that.

: $1 ~ $2 ~ and $3 ~ and $1 $2 and or $2 $3 and or dup bdd
: $3 ~ $2 ~ and $1 ~ and $3 $2 and or $2 $1 and or dup bdd

The proof is that while these two numbers represent
different AST nodes, these two items both reference
the exact same BDD node.

* =00:30= 06 briefest possible intro to nids
They're 64-bit data structure that fits nicely in a register.
I actually started with pointers, but for a lot of different
reasons, eventually adopted this idea instead.

The NIDs for variables and con stants contain everything you
would ever need to know about the nodes, so you don't
actually need to have those nodes in memory. Which means
for simple nodes, there's no longer anything for the pointer
to point to anyway.

And if you think about that idea long enough,
maybe you'll start to see why that magic number
4,294,967,296 is on my favorites list.

Don't worry. We'll get there.

But first let's talk about that other number.

* =01:00= 07 Primorials
** a. tests and benchmarks
Okay, so far, we've only been looking at these tiny functions of three variables.

But but BDDs can work with hundreds or thousands of variables, and even with
just a few more inputs, complicated functions can result in huge BDDs, and
those are the cases I want to work with.

As I said, bex has become something of an exercise in optimization for me.

In order to make sure I'm not breaking anything, I need a suite of test
problems that bex can run quickly, so I can run the tests after every change.

And in order to tell whether a change actually speeds things up, I need a
benchmark - something that takes a long time to solve, so I can see whether
the time improves.

** b. standard test problem

So that's where this number comes in.

: */ p: i. 15

(This is a language called J. It's a full programming language,
but it's also kind of an executable math notation, and probably
one of the best desktop calculators you can get.)

It executes right to left, so:

: 15                NB. the number fifteen
: i. 15             NB. the first fifteen non-negative integers
: p: i. 15          NB. the first fifteen primes
: */ p: i. 15       NB. their product (literally insert a multiplication sign between them)

A product of the first n primes is apparently called a primorial,
which I suppose is a combination of the words prime and factorial.

This primorial happens to be the largest one whose binary
representation can fit in a 64-bit register.

:   (2^64) > */ p: i. 15
: 1
:   (2^64) > */ p: i. 16
: 0

** the problem to solve

The benchmarking problem I set for bex is to figure out all
the ways you can multiply two thirty-two bit numbers together
to get this number.

Or in other words, factor the number. I could have asked it to
factor any big number, but with primorials in particular it's
really easy for me as the test author to generate the correct
answer.

** factors
The trick is to take the fifteen primes and find every possible
way to divide them into two groups.

Well, that part's easy. You just count to 2^15 in binary.

Here's a smaller example that fits on the screen:

:   */ p: i. 15
:   */ p: i. n=: 15     NB. let's give the 15 a name
:   */ p: i. n=: 4      NB. and drop it to 4
:   i. n=: 3            NB. first three ints
:   i. 2^n =: 3         NB. count to 2^3
:   #: i. 2^n =: 3      NB. same thing in binary

Now we can use these patterns to group the primes.

:   (#: i. 2^n) </."1 p:i.n =: 3     NB. use t

You can see it duplicates the list.
That's because half of the binary representations are just
the other half flipped.

: viewmat #: i. 2^n

So we can just use half of them

:  #: i. 2^n-1

and put a 0 on the left so each line still matches the numbers of primes

:  0 ,. #: i. 2^n-1

Now we have every unique grouping of factors:

:   (0 ,. #: i. 2^n-1) </."1 p:i.n =: 3


And we can do the same thing for our original 15.

But the question was which 32-bit factors, and some of these numbers are too big.

So multiply the contents of each box:

: */L:0

then we can ditch the boxes completely:

: >

just as a sanity check, that gives us:

: #

16384

if we factor that, we get

: q: 16384
: # q: 16384

2 to the 14th power. which is exactly what we asked it for.

So that's all pairs of integers that multiply to our primorial.

But we want to select the ones where both numbers are less than 2^32

: ({~ [: I. [: *./"1 <&(2^32))

This is too much J to explain in detail right now, but it
literally says select using the indices where all the items
on a row are less than this number.

That gives us exactly...

:    # ({~ [: I. [: */"1 <&(2^32)) > */L:0 (0 ,. #: i. 2^n-1) </."1 p:i.n =: 15
: 3827

... 3827 unique pairs of 32-bit numbers that factor into our number.

** the rust code
# show bdd-solve

And after a little formatting, those numbers and the primorial itself
go into this rust file, and there's our test case.

#+begin_src rust
find_factors!(BDD, X32, X64, K as usize, factors(), false); }
#+end_src

It's a macro that says use a BDD to find all pairs of 32-bit
factors of the 64-bit number K, (arranged so that the first
number is less than the second), and then check that the
answers match this list.

(The last parameter says whether or not to show some extra
debug information. It really ought to be a command line
parameter, but whatever.)

So let's see what happens when we run this.

: cargo run --bin bdd-solve

Off to a good start.

This would be a good time for my scroll lock key to actually work,
but since it doesn't I can just scroll up a little to freeze the
display.

And there's a bunch of stuff about ands and xors, but it also says
step xxx of 7997 so we're already at xxx percent.

Unfortunately, that number is fairly misleading. The way the
current solver works, it knows how many steps it will take to
construct the solution, but it doesn't know how long each step
is going to take.

You can see already it's slowing down.

** So what is it trying to do? (chess story)

If it works, then the output will be a BDD on 64 input bits,
and 1 output bit, and it'll represent the function that returns
true when the first 32 bits multiplied by the second 32 bits
is this number K.

Since it has 64 input bits, that means the truth table is
2^64 bits wide, which is an INSANELY large number.

This is that story about the grains of rice on the chessboard.
As payment for inventing the game of chess, you ask the emperor
for a grain of rice on the first square, two in the second square,
double each time, and after a while, the emperor's accountants
figure out what's going on and chop your head off.

So yeah, the truth table is 2^64 entries wide. Each entry
represents a pair of 32-bit numbers that might or might
not multiply, but we happen to know that there are only
3,827 such numbers.

A BDD ought to be able to represent this truth table fairly
efficiently. The problem is just constructing it from the
problem statement.

** show it working
** give up

# I actually stopped this around 5% because my computer locked up.
# It was right after I got up to go to the bathroom so I suspect
# the thread just got moved to the foreground and didn't want to
# give back control. Either way, I should probably manually stop
# the program.

I wanted a problem with an easy answer to generate and check
but that would be hard for bex.

I knew multiplication is particularly hard for bdds - meaning you
wind up with a very large bdd.

But I didn't know HOW hard it would be.

Turns out it's really really hard.
The percentage numbers are somewhat misleading.
It's going to get slower and slower as it goes along.

I've never actually seen this program finish,
and it's not garbage collecting, so I think last time
i tried, it just churned for a few days, and then finally
crashed when it ran out of RAM.

So yeah, it turned out my initial problem is way too
hard for bex to solve right now, and so the reason
that number is always on my mind is simply that it
represents a pretty ambitious goal to shoot for.

* bex is exercise in optimization, and anf is a possible optimization
one idea is algebraic normal form
i don't know if it's an optimization or not yet.

* =01:00= algebraic normal form.

meanwhile, i had another idea

bdd says you can represent any boolean function with if/then/else.
obvious just by looking at how the binary tree maps to the truth table.

assertion:

  1. you can represent any boolean function with (and, xor, 1)
  2. and in particular, we can make a bdd-like structure
     that uses a different ternary function:

: bdd: V ? H : L         NB. if V then H else L  ("var", "hi", "lo")
: anf: V * H + L         NB. + is "plus mod 2"
: anf: L ~: V *. H       NB. j syntax

nand is sufficient to generate all 16 boolean functions.
fun to work out for yourself. here's a proof in J:

https://github.com/tangentstorm/tangentlabs/blob/master/j/nornand.ijs


p =: 0 0 1 1
q =: 0 1 0 1

p na q

proof: nand = (1 & xor)@AND

(show the 16 2-bit truth tables?)


functionally complete operator sets
NAND = AND, XOR, T
https://en.wikipedia.org/wiki/Functional_completeness


: (1+a)+(b+c)+(a+b)                // 6 terms (4 unique)
:  1+a + b+c + a+b                 // simply remove the parens
:  1   + c                         // cancel a, b


: (a+b+c)(d+e+f)                     / 3+3 = 6 terms
: ad+ae+af+bd+be+bf+cd+ce+cf         / 3x3 = 9 terms
: a(d+e+f) + b((d+e+f) + c(d+e+f))   / 6 terms (not counting 0)

* =00:30= langlet transform
: https://en.wikipedia.org/wiki/Zhegalkin_polynomial
* =01:00= visual ANF : numbers at the bottom

truth table <-> anf
we can think of that number as representing a set of 32 items.
langlet, power set
power set.

:  |:#:i.2^5
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1
0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1
0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1
0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1

:  viewmat |.&.|:~:/\^:(<32)32#1

you can kinda see that the first term in anf always corresponds
to the first entry in the truth table.

for every slot in the truth table, there's exactly one pattern
that starts in that column. so to get the first 1, you have to
start with that pattern, and then the other patterns you xor
on top of it have to be shorter because all the other bits in
the truth table are off to the right.

And by the way, these patterns repeat in the same order no matter
how wide you make the table.

# show 2^64, 2^1024

In a way, these simple patterns repeating off to the right are like
the primes when it comes to truth tables.

And when you think when you consider these patterns to be ongoing, infinite
sequences that always appear in the same order no matter how many variables
you have, then it doesn't really make sense that their names should
constantly change depending on how many variables you have.

Numbering from the bottom, this pattern is always x0, this is always x1,
and so on.

This is what convinced me to renumber these with the names at the bottom.

And so finally, that's where the number 2^32 comes in.

* =01:00= a new idea: truth tables in the NID
as you can see, with 32 bits, you can represent an entire
truth table for a function of 5 variables.

# show the NID

That means I could fit an entire 5-variable truth table
directly in these 32 bits of a NID.

: X =             4,294,967,296

Since that pattern always refers to x0, why not just use that
pattern as the NID for x0? And this one for x0 anded with x1?

Since the truth table contains everything you need to know
about the function, that's 4.29 billion possible nodes that
can be described entirely by their NID,
and therefore 4.29 billion nodes that never actually have
to be allocated.

And now that we're numbering from the bottom up, it means
that for every single BDD
and every single ANF graph
in the universe,
the bottom six rows of nodes (five variables and the two constants)
can be described completely in terms of 32-bit truth tables,
which can be operated on directly in the CPU, without
needing to reach out to actual nodes in ram,
and without looking anything up in a cache.

In other words, bex can go a whole lot faster.

# show nano ast

So for example, this entire nano test case would go
away, because every single node in this AST has
fewer than five inputs. Instead of allocating a
new AST node to AND these two inputs, bex could
just directly calculate the truth truth table,
and the whole expression could just be replaced
by one single node.

# show next test
and for this one, all these nodes could go away
for the same reason, because they use only the
first five variables.

It's interesting that these nodes also use only
five variables, but they're not the lowest five.

Maybe I could still use the same idea, though,
and just have this top part of the nid point to
a list of the variables involved.

In that case, it doesn't really matter whether
the smallest numbered inputs are at the bottom,
but it still makes a pretty good default case.



* -- timed --------------------------------------
* =00:30= closing
i was hoping to actually implement those ideas for this video,
but i'm out of time, and i've probably talked long enough already.

but if people find it interesting, maybe i'll make a
follow-up video someday.

meanwhile, there's a link to the bex source code on github
in the video description, as well as other related links.

check out the other videos in my channel for more about J,
and check out the #magafavnumbers playlist to see more videos
about interesting giant numbers, or to upload your own.

Anyway, thanks for watching, and I'll see you next time!


* --- end here --------------------------------------


* TODO make the change to const NIDs (on a new branch)
I always like to show how to actually make a change, and this seems like a good one.

** TODO collect some more metrics
- number of steps
- count each kind of hash lookup, and whether it was found
- count calls to ITE::norm (can do this in dispatcher as it sends/receives the answers)
- or just analyze the wip table when the solution comes in to see what's still wip?

** TODO =NID::is_tbl=
- add a new bit for tables (or just use existing T) ?
- redefine =is_const= to specifically check equality for I/O

** TODO implement directly in AST for now.
- completely eliminate the work from nano test

** TODO render const nodes with braille
Mostly because it can hold a 5-variable truth table or a
5-variable anf expression. braille font
binary decision diagrams
bdd: https://jsfiddle.net/tangentstorm/bLbayo6c/

** TODO implement whenhi / whenlo
this should let it get down to I,O and work for BDD automatically.

** TODO how to handle for ANF?
- simple const-const is easy
- how to do const + true ANF?
- i think implementing =when_hi= and =when_lo= /might/ be sufficent.

* TODO test the change!
- compare the steps taken for each node
- how to handle for AST?

* TODO back to our number

want it to run faster than brute force
but still maintain the benefits of caching

next higher numbers: truth table size doubles with each new input bit

but that means the number of possible truth tables squares
wouldn't actually be hard to store a truth table that big.
2^32 bits = 500 MB uncompressed. (why? well 2^32 pointer gives you 4 gb,
but that's bytes, and we need bits, so divide by 8. 4g / 8 = 0.5g, or 500mb)
That's a pretty huge file, but it's not *that* huge.
Maybe it's possible to have multiple worker threads generate the input truth
table in linear ram from a BDD, and a stream processing thread to combine them.
BDD itself is a compression algorithm, but maybe other compression algorithms
could be used to unpack truth tables.

* TODO bex/bdd community?
link in the description to a forum
Remains an exercise in optimization.

https://www.reddit.com/r/bex_rs/new/

* TODO future directions(?)
# probably move this to a document on bex
- refactor and reuse BDDSWarm components for ANF, future VHL bases
- generalize the wip/distributed solver
- extend the raw truth table idea to arbitrary registers
  - process with streaming instructions or the gpu
  - convert to/from BDD for compression
- mixed representation for wip
  (meaning registers at the bottom, bdd up top)
- lazy solving of regions
  (solve truth table left to right to reach first answer faster)
- combine bottom-up and top-down solving
- dynamic sifting (variable permutations)
- new base formats
  - zdd
  - bic
  - cnf ? sat solver
  - aig ? https://en.wikipedia.org/wiki/And-inverter_graph
- gpu and fpga workers
- var sets for functions of n vars, no matter which n they are
  there might be 500 input variables, but only using 15.
- better AST
  - track topmost variable in NID even for AST
  - allow any number of arguments
  - full combinatory logic
  - operations on xints (nid arrays)
- import/export stored functions
- apply functions across base types

* ------------------------------------------

* TODO more example(s) from old repo?
* TODO novel parts about bex

- algebraic normal form
- shell

* tangents
** 2^32-1

x-1 = largest 32-bit unsigned integer
      "negative zero" in ones compliment

four bytes:
  more colors than on your computer screen
  brightest color on screen
  maximum number of ip addresses
  four gb of ram

** too small

little more than half the population of earth
  https://en.wikipedia.org/wiki/World_population

414 people on earth have more money than that.
   https://www.forbes.com/billionaires/
$196.29 billion USD bezos
  21.43 trillion USD (2019)

zimbabwe:
  https://en.wikipedia.org/wiki/Hyperinflation#Ten_most_severe_hyperinflations_in_world_history
  https://en.wikipedia.org/wiki/Zimbabwean_dollar

* --- thoughts from train
- sha256 as motivator? solving tools in general aren't up for the challenge
- move the future directions to a separate file
- how you can get involved
- nid was gently encouraged by rust (working with the grain of the language)
  - might say not memory safe, but it can be saved and copied

- anf: in addition, the anf base attempts to do the and and xor operations on the data in this form
- the idea is that when you're manipulating formulas, there's likely to be a lot of reuse from
  operations distributing over each other, and often, that can be captured near the top
  of the graph, without necessarily merging every leaf.


- when you're just talking about formulas, the variable order doesn't matter.
- i called this pattern a, but in a traditional bdd, you number from the top down
- but if you think about these as infinite patterns that appear in almost every expression,
- it makes sense for them to always have the same name"

- early on; emphasise canonical representations. bdd and anf are both cannonical. ast is not.

- explain the "combining functions efficiently" paradox: compression reduces a lot of steps because you can work at the top of the dag.
- one operation at the top might match 2^n operations at the bottom.
- but there is also overhead of fetching nodes from memory
- so it makes sense to balance the two
- I think how big the "registers" are might have to do with how much entropy you expect your function to have.
- the more regularity and structure, the more working near the top will save work
- the more random your data, the better it is to stream
- so it might make sense to let users configure this on each run.


* bdd swarm tangent

But when I implemented it, something kinda interesting
happened.

The plan was to chop up the work for constructing a BDD,
and divide it among the the threads - one thread per CPU
core.

So I figured if I had 6 CPU cores, it would run 6 times
as fast.

Well the little laptop I use on the train has only has two
cores, but what happened is that when I switched over to the
swarm, some of the steps that used to take 20 seconds
started taking 0.

So it was a completely non-linear speedup.

So what happened?

I'm actually not completely sure.

I suspect that


* bex internals: too much to talk about here, and not relevant for intro
** TODO =00:30= nid: optimizations nudged by rust

Each one of these things is what I call a NID.
Nid is short for "node identifier".

Internally, each of them is a 64-bit number,
broken down into fields.

At the moment, AST nodes don't have a top
variable associated with them, so they just
show up as numbers.

For BDD nodes, it shows you the top level
variable, and also whether or not the node
is inverted.

That's because if two nodes are exactly the
same except all the ones and zeros are swapped.
That's the invert or "not" operation, then
they share the same entry in the database,
and only the bit changes.

So that means if you have a node and you want
to invert the whole function...

: dup not

... then bex doesn't even need to load the graph
into memory. It just flips that one bit directly
in the NID.

** =00:00= ITE::norm
You might ask why use NIDs instead of pointers.

I actually started out using pointers.

The thing is, making a memory and thread safe
graph structure out of pointers is hard to get right,
and in rust you have to do it right, because unless you
wrap everything in an unsafe block rust won't let you
make mistakes.

So I tried just storing all my nodes in a vector, and
using node ids, and suddenly the code was a whole lot
simpler, and I was getting a lot more done.

But also, being able to pack metadata into a single
register means there are some operations you can do
directly on NIDs, without having to follow a pointer
at all.

So for example, if you run a profiler on bex, and you
pretty much anything with a BDD, you'll probably find
that almost all the time is actually spent in this
function called ITE::norm.

ITE means "if then else". It operates on three NIDs,
and it really needs to know whether the node is inverted,
and which input variable the node branches on.

Since that stuff is stored in the NID itself, this
function can do its work entirely in the CPU, without
reaching out to RAM at all.

** =00:30= wip: multi-core support

The examples we've tried so far only take a few
milliseconds to run, but in real life, if you want
to use this to lay out a circuit or as part of a
SAT solver, you have to deal with huge expressions
of hundreds or thousands of variables.

One of the things I was interested in with the rust
implementation was multi-threaded support.

# show https://www.rust-lang.org/

Rust's slogan is that it empowers everyone to build
reliant and efficient software.

And in particular, unless you explicitly opt out
of the checking system, it catches all sorts of
mistakes when it comes to thread and memory safety.

Over the years, I've always kind of avoided or
minimized multi-threading in my code just because
it really is so hard to get right, and I'm not
usually working on things where speed is all that
important.

But rust was promising to make multi-threading easy,
and I decided that I'd treat bex as sort of an
ongoing excercise in optimization.

So, I spent some time on it, and made a pretty
clunky multi-threaded worker for bex called the
BDDSwarm.

One of my current plans is to clean the swarm code up
and apply the same idea to some of the other graph
representations that bex supports, so maybe someday
I'll make another video to explain it.

This was my first serious attempt at a multi-threaded
system in my life, and the code for that part is way
too complicated and messy to talk about in this video.

What's important for this story, though, is that once
I got the multi-core stuff working, it started to look
like maybe bex could actually become a useful
application at some point.

And so I decided to come up with some standardized
benchmarks.


** =1:00= Inside the solver
*** TODO talk about xints
*** what's the point?

But you might ask, what's the point of this?

First of all, I already know the answer to the problem,
because that's what I started with.

Second of all, who cares?

The point isn't really to solve this particular problem.
The point is to solve whatever problem you throw at it
as quickly as possible.

The solution algorithm I'm using is pretty simplistic.

*** So what can we do?

Well one nice thing about the factoring problem is that
it scales way down.

A few versions of the problem actually run in a few seconds
on my machine.

: cargo test

Some of these are just general unit tests.

By the way, if you add one character to the j program then instead of
the final product, you'll see the running product, which is the first
15 primorials.

: */\p:i.15
: ,.*/\p:i.15

So currently, bex can solve the first four of these fast enough to
run as unit tests.

: cargo test --lib nano_bdd

#+begin_src rust
#[test] pub fn test_nano_bdd() {
  use {bdd::BDDBase, int::{X2,X4}};
  find_factors!(BDDBase, X2, X4, 6, vec![(2,3)], false); }
#+end_src

let's run again with that false changed to true.

*** TODO describe the diagrams that show up
eq.svg is the multiplication
lt.svg is the condition that x<y
ast.svg is the combination of those two
x-final.svg is the final AST

**** TODO show node numbers in the AST (before and after renumbering)
**** TODO render and show each step as a (stop-motion) "animation"

*** TODO generate diagrams with the original and reverse orders
use custom shapes https://www.graphviz.org/doc/info/shapes.html
now that #1 is at the bottom...

** slowtests and import/export

210 is an 8-bit number, and the tests look for two four-bit factors.
If I ask it to search for two 8-bit numbers that multiply to 210 as
a 16-bit number, then it winds up taking 11 minutes. Of course I don't
actually need all 16 bits in the answer, so it might be interesting
to have it discard the 16 bits in the AST stage.

(Which means it ought to also take 11 minutes for solving 30030)

But also, the way this works, it generates the entire BDD for
the multiplication of two input numbers from scratch in a fresh BDD
base every single time, even though this is completely generic.
There's no reason this function couldn't be cached to disk and
loaded into the base on demand.

Then it would just be a matter of pulling that pre-compiled function
in from a stored library.

Bex doesn't yet have an import feature at runtime, but you can save
and entire bases. Import and export should only be a few lines of code.
It's not hard at all, just something I haven't gotten around to.

*** TODO make and show a ticket for import/export

also there could be one stored multiplication database, 2*n output
bits for 2*n input bits, and you could just look at the ones you wanted.

import/export is easy, but i'd also have to teach the solver when to
use the imported function, which means having AST nodes aware of n-bit
ints... Which means making the AST representation much more expressive
in general.

(this is something i'm thinking about)


* TODO pascal git is missing some pieces
* cut anf example
: (1+a)(b+c)(a+b)                  // 6 terms (4 unique)
: (1+a)(b(a+b)+c(a+b))
: (1+a)(b(a+b)+ca+cb))
: (1+a)(ba+bb+ca+cb)
: (1+a)(ba+b+ca+cb)
: (ba+b+ca+cb)+a(ba+b+ca+cb)
: (ba+b+ca+cb)+ba+ba+ca+cba
: ba+b+ca+cb+ba+ba+ca+cba
: ab+b+ac+bc+ab+ab+ac+abc
: ab+ab+ab+abc+ac+ac+b+bc          // cancel
:       ab+abc      +b+bc          // 4 terms (4 unique)
: a(b+bc)+(b+bc)                                              b(a+ac+1+c)      // not allowed
: a(b(1+c)) + (b(1+c))                                        b(1+a+ac+c)
: a(b(1+c)) + b(1+c)                                          b(1+a(1+c)+c)



** xor fiddle

xor: https://jsfiddle.net/tangentstorm/vkmLq2bj/latest/
